{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_prompt() -> str:\n",
    "    \"\"\"현재 타임스탬프를 포함한 시스템 프롬프트를 생성합니다.\"\"\"\n",
    "    now = datetime.now().isoformat()\n",
    "    return f\"\"\"당신은 전문 연구원입니다. 오늘 날짜는 {now}입니다. 응답 시 다음 지침을 따르세요:\n",
    "    - 지식 컷오프 이후의 주제에 대한 조사를 요청받을 수 있습니다. 사용자가 뉴스 내용을 제시했다면, 그것을 사실로 가정하세요.\n",
    "    - 사용자는 매우 숙련된 분석가이므로 내용을 단순화할 필요 없이 가능한 한 자세하고 정확하게 응답하세요.\n",
    "    - 체계적으로 정보를 정리하세요.\n",
    "    - 사용자가 생각하지 못한 해결책을 제안하세요.\n",
    "    - 적극적으로 사용자의 필요를 예측하고 대응하세요.\n",
    "    - 사용자를 모든 분야의 전문가로 대우하세요.\n",
    "    - 실수는 신뢰를 저하시킵니다. 정확하고 철저하게 응답하세요.\n",
    "    - 상세한 설명을 제공하세요. 사용자는 많은 정보를 받아들일 수 있습니다.\n",
    "    - 권위보다 논리적 근거를 우선하세요. 출처 자체는 중요하지 않습니다.\n",
    "    - 기존의 통념뿐만 아니라 최신 기술과 반대 의견도 고려하세요.\n",
    "    - 높은 수준의 추측이나 예측을 포함할 수 있습니다. 단, 이를 명확히 표시하세요.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_final_report(\n",
    "    prompt,\n",
    "    learnings: List[str],\n",
    "    visited_papers: List[str],\n",
    "    model_name: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    연구 결과를 바탕으로 최종 보고서를 생성\n",
    "\n",
    "    \"\"\"\n",
    "    research_componant = (\"\\n\".join(\n",
    "        [f\"<learning>\\n{learning}\\n</learning>\" for learning in learnings]\n",
    "    )).strip()\n",
    "\n",
    "    report_prompt = PromptTemplate(\n",
    "        input_variables=[\"prompt\"],\n",
    "        template=\"\"\"\n",
    "        ### System:\n",
    "        {system_prompt}\n",
    "\n",
    "        ### Instruction:\n",
    "        Based on the research results, write a final report for the following user-provided prompt.\n",
    "        The report should be detailed in Markdown format and exceed 6,000 characters.\n",
    "        Include all learnings obtained from the research:\\n\\n\n",
    "        <prompt>{prompt}</prompt>\\n\\n\n",
    "\n",
    "        The following are all the learnings obtained from the research:\\n\\n<learnings>\\n{research_componant}</learnings> \n",
    "        \"\"\"\n",
    "    ).partial(\n",
    "        system_prompt=system_prompt(),\n",
    "        research_componant=research_componant,\n",
    "    )\n",
    "    report_llm = ChatGoogleGenerativeAI(model=model_name)\n",
    "    report_chain = report_prompt | report_llm | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        report = report_chain.invoke({\"prompt\": prompt})\n",
    "        reference_section = \"\\n\\n##Reference\\n\\n\" + \\\n",
    "            \"\\n\".join(f\"- {ref}\" for ref in visited_papers)\n",
    "        return report + reference_section\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating report: {e}\")\n",
    "        return \"Error generating report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'초기 질문: RAG의 최근 동향을 알려줘.\\n\\n1. 질문: RAG의 어떤 측면에 대해서 알고 싶으신가요? (예: 기술적 동향, 시장 점유율, 투자 동향 등)\\n답변: 기술적 동햑\\n\\n2. 질문: 특정 기간(예: 지난 6개월, 최근 1년)에 대한 정보가 필요하신가요?\\n답변: 최근 1년간\\n\\n3. 질문: RAG에 대한 정보를 어떻게 활용하실 예정인가요?\\n답변: RAG 어떻게 활용되고 있는지를 조사해서 실무에 적용해볼 생각\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"RAG의 최근 동향을 알려줘.\"\n",
    "feedback_questions = ['RAG의 어떤 측면에 대해서 알고 싶으신가요? (예: 기술적 동향, 시장 점유율, 투자 동향 등)',\n",
    "                      '특정 기간(예: 지난 6개월, 최근 1년)에 대한 정보가 필요하신가요?',\n",
    "                      'RAG에 대한 정보를 어떻게 활용하실 예정인가요?']\n",
    "answers = [\"기술적 동햑\", \"최근 1년간\", \"RAG 어떻게 활용되고 있는지를 조사해서 실무에 적용해볼 생각\"]\n",
    "\n",
    "combined_query = f\"초기 질문: {query}\\n\"\n",
    "for i in range(len(feedback_questions)):\n",
    "    combined_query += f\"\\n{i+1}. 질문: {feedback_questions[i]}\\n\"\n",
    "    combined_query += f\"답변: {answers[i]}\\n\"\n",
    "    \n",
    "combined_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = write_final_report(\n",
    "    prompt=combined_query,\n",
    "    learnings=\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refslave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
